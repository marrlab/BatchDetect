{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Effect detection class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install ./../../BatchDetect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from histaugan.model import EfficientHistAuGAN\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create metadata dataframe from clini_table and folder structure\n",
    "clini_table = pd.read_excel('/lustre/groups/peng/datasets/histology_data/clini_tables/TCGA-CRC-DX_CLINI.xlsx')\n",
    "\n",
    "# metadata with columns: file, label (MSI-H), submission site\n",
    "base_dir = Path('/lustre/groups/shared/users/peng_marr/BatchDetect/')\n",
    "patch_list = list(base_dir.glob('BatchDetectTCGA/*/TCGA*/*.jpeg'))\n",
    "print('Number of patches:', len(patch_list))\n",
    "\n",
    "submission_site = [patch.parent.parent.name for patch in patch_list]\n",
    "label = [clini_table.isMSIH[clini_table['PATIENT'] == patch.parent.name[:12]].item() for patch in patch_list]\n",
    "metadata = pd.DataFrame(list(zip(patch_list, label, submission_site)), columns=['file', 'label', 'dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.array(submission_site), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator(Dataset):\n",
    "\n",
    "    def __init__(self, metadata, transform=transforms.ToTensor()):\n",
    "        self.metadata = metadata.copy().reset_index(drop = True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        ## get image and label\n",
    "        file_path = self.metadata.loc[idx,\"file\"]\n",
    "        image= Image.open(file_path)\n",
    "\n",
    "        label = self.metadata.loc[idx,\"label\"]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image) \n",
    "            \n",
    "        return image.float(), label, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_path = base_dir / 'ctranspath_features_efficient_histaugan*2.csv'\n",
    "\n",
    "if X_features_path.exists():\n",
    "    X_features = pd.read_csv(X_features_path)\n",
    "else: \n",
    "    feature_dim = 768\n",
    "    X_features = pd.DataFrame(index = metadata.index, columns = [\"X\" + str(i+1) for i in range(feature_dim)])\n",
    "    \n",
    "    # load feature extractor\n",
    "    from swin_transformer import swin_tiny_patch4_window7_224, ConvStem\n",
    "\n",
    "    feature_extractor = swin_tiny_patch4_window7_224(embed_layer=ConvStem, pretrained=False)\n",
    "    feature_extractor.head = nn.Identity()\n",
    "\n",
    "    ctranspath = torch.load('/home/haicu/sophia.wagner/models/ctranspath.pth')\n",
    "    feature_extractor.load_state_dict(ctranspath['model'], strict=True)\n",
    "    feature_extractor.to(device)\n",
    "    feature_extractor.eval();\n",
    "    \n",
    "    # load efficient histaugan model\n",
    "    checkpoint_dir = Path('/lustre/groups/peng/workspace/sophia.wagner/logs/histaugan_lightning/checkpoints')\n",
    "    run = 'l1_a_cc+correct_adv_cls+attr_VAE+128'\n",
    "    model_name = 'Efficient-HistAuGAN-epoch=01-l1_cc_loss_val=0.72.ckpt'\n",
    "\n",
    "    model = EfficientHistAuGAN.load_from_checkpoint(checkpoint_dir / run / model_name)\n",
    "    model = model.to(device)\n",
    "    model.eval();\n",
    "    opts = model.opts\n",
    "    \n",
    "    # load dataset\n",
    "    # transform = transforms.Compose([\n",
    "    #     transforms.Resize((224, 224)),\n",
    "    #     transforms.ToTensor(),\n",
    "    # ])\n",
    "    transform = transforms.Compose([\n",
    "        # transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "    dataset = DatasetGenerator(metadata, transform)\n",
    "    dataloader =  DataLoader(dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # forward pass through the feature extractor\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast():\n",
    "            for image, _, idx in tqdm(dataloader): \n",
    "                image = image.to(device)\n",
    "                lowres = F.interpolate(image, size=(128, 128))\n",
    "                z_content, (mu, _) = model.encoder(lowres)\n",
    "                z_random = torch.randn_like(mu) * 2\n",
    "                image = model.generator(image, z_content, z_random)\n",
    "                image = F.interpolate(image, size=(224, 224))\n",
    "                features = feature_extractor(image).cpu().numpy().reshape((len(idx), feature_dim))\n",
    "                X_features.loc[idx,:] = features\n",
    "                \n",
    "    X_features.to_csv(X_features_path)\n",
    "\n",
    "    del dataset\n",
    "    del dataloader\n",
    "    del feature_extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see if there is a batch effect in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchdetect.batchdetect import BatchDetect\n",
    "\n",
    "bd = BatchDetect(metadata.loc[:,[\"label\",\"dataset\"]], X_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.low_dim_visualization(\"pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.low_dim_visualization(\"tsne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.low_dim_visualization(\"umap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anova test of principal components vs. labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.prince_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification test of  RF vs a random classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.classification_test(scorer=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
